{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90356e48",
   "metadata": {},
   "source": [
    "\n",
    "# CUDA Kernel Performance Comparison\n",
    "\n",
    "This notebook compares two CUDA convolution kernels:\n",
    "- **Standard tiled kernel**\n",
    "- **PTX-optimized kernel**\n",
    "\n",
    "We measure and visualize:\n",
    "- Execution time\n",
    "- Memory throughput (based on roofline estimates)\n",
    "- Performance implications for CNN-like loads\n",
    "\n",
    "Ensure you have `nvcc`, `pycuda`, and a CUDA-capable GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pycuda matplotlib --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3279fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import run, PIPE\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aabb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compile_kernels():\n",
    "    run([\"nvcc\", \"-arch=sm_52\", \"-ptx\", \"kernel1.cu\", \"-o\", \"kernel1.ptx\"], check=True)\n",
    "    run([\"nvcc\", \"-arch=sm_52\", \"-ptx\", \"kernel2.cu\", \"-o\", \"kernel2.ptx\"], check=True)\n",
    "    print(\"Kernels compiled.\")\n",
    "    \n",
    "compile_kernels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70baf0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "def load_module(file):\n",
    "    with open(file, 'r') as f:\n",
    "        return SourceModule(f.read())\n",
    "\n",
    "def run_kernel(mod, func_name, image_size=(256, 256), channels=3, block=(16,16,1)):\n",
    "    func = mod.get_function(func_name)\n",
    "    height, width = image_size\n",
    "    mask_width = 5\n",
    "\n",
    "    I = np.random.rand(height, width, channels).astype(np.float32)\n",
    "    M = (np.random.rand(mask_width, mask_width) / (mask_width * mask_width / 4.0)).astype(np.float32)\n",
    "    P = np.zeros_like(I).astype(np.float32)\n",
    "\n",
    "    I_gpu = cuda.mem_alloc(I.nbytes)\n",
    "    M_gpu = cuda.mem_alloc(M.nbytes)\n",
    "    P_gpu = cuda.mem_alloc(P.nbytes)\n",
    "\n",
    "    cuda.memcpy_htod(I_gpu, I)\n",
    "    cuda.memcpy_htod(M_gpu, M)\n",
    "\n",
    "    grid = ((width + block[0] - 1) // block[0], (height + block[1] - 1) // block[1])\n",
    "\n",
    "    start = cuda.Event()\n",
    "    end = cuda.Event()\n",
    "    start.record()\n",
    "    func(I_gpu, M_gpu, P_gpu,\n",
    "         np.int32(channels), np.int32(width), np.int32(height),\n",
    "         block=block, grid=grid)\n",
    "    end.record()\n",
    "    end.synchronize()\n",
    "    ms = start.time_till(end)  # milliseconds\n",
    "\n",
    "    cuda.memcpy_dtoh(P, P_gpu)\n",
    "    return ms, I, P\n",
    "\n",
    "kernel1_mod = load_module(\"kernel1.cu\")\n",
    "kernel2_mod = load_module(\"kernel2.cu\")\n",
    "t1, _, _ = run_kernel(kernel1_mod, \"convolution\")\n",
    "t2, _, _ = run_kernel(kernel2_mod, \"convolution_with_ptx\")\n",
    "print(f\"Kernel 1 time: {t1:.3f} ms\")\n",
    "print(f\"Kernel 2 time (with PTX): {t2:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['Standard', 'PTX-Optimized']\n",
    "times = [t1, t2]\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(labels, times, color=['skyblue', 'orange'])\n",
    "plt.ylabel(\"Execution Time (ms)\")\n",
    "plt.title(\"Kernel Timing Comparison\")\n",
    "plt.grid(True, axis='y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
