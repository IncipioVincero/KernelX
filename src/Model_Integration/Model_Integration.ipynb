{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Integration: Convolution Kernels\n",
        "\n"
      ],
      "metadata": {
        "id": "JhL81ZJehubY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "id": "jfWQytq2jGIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "FWvOqdUhh0x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \"Vanilla\" Convolution and PTX Convolution"
      ],
      "metadata": {
        "id": "V6On6d3TiWZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class VanillaConv2D(torch.nn.Module):\n",
        "    def __init__(self, mask: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.mask = mask.contiguous().float().cuda()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        B, C, H, W = x.shape\n",
        "        out = torch.zeros_like(x)\n",
        "        for b in range(B):\n",
        "            custom_conv.vanilla_convolve(x[b], self.mask, out[b])\n",
        "        return out\n",
        "\n",
        "\n",
        "class PTXConv2D(torch.nn.Module):\n",
        "    def __init__(self, mask: torch.Tensor):\n",
        "        super().__init__()\n",
        "        self.mask = mask.contiguous().float().cuda()\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        B, C, H, W = x.shape\n",
        "        out = torch.zeros_like(x)\n",
        "        for b in range(B):\n",
        "            custom_conv.ptx_convolve(x[b], self.mask, out[b])\n",
        "        return out"
      ],
      "metadata": {
        "id": "VGOldbsJiBkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "9KOLaNubilRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from setuptools import setup\n",
        "from torch.utils.cpp_extension import CUDAExtension, BuildExtension\n",
        "\n",
        "setup(\n",
        "    name='custom_conv',\n",
        "    ext_modules=[\n",
        "        CUDAExtension('custom_conv', [\n",
        "            'convolution.cu',\n",
        "            'convoluion_inline_ptx.cu',\n",
        "        ])\n",
        "    ],\n",
        "    cmdclass={'build_ext': BuildExtension}\n",
        ")"
      ],
      "metadata": {
        "id": "dEKKZLQyinyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Benchmarks"
      ],
      "metadata": {
        "id": "kF6_gGM4ivKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.benchmark as benchmark\n",
        "import VanillaConv2D, PTXConv2D\n",
        "\n",
        "\n",
        "def benchmark_model(model, input_tensor, label, warmup=10, runs=50):\n",
        "    for _ in range(warmup):\n",
        "        _ = model(input_tensor)\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    timer = benchmark.Timer(\n",
        "        stmt='model(x)',\n",
        "        setup='from __main__ import model, x',\n",
        "        globals={'model': model, 'x': input_tensor},\n",
        "        num_threads=1,\n",
        "        label=label\n",
        "    )\n",
        "    results = timer.blocked_autorange(min_run_time=1.0)\n",
        "    print(results)\n",
        "    return results.median, results.stddev\n",
        "\n",
        "def run_benchmarks():\n",
        "    device = 'cuda'\n",
        "    B, C, H, W = 4, 3, 256, 256\n",
        "\n",
        "    input_tensor = torch.rand(B, C, H, W, device=device)\n",
        "    kernel = torch.ones(5, 5, device=device) / 25.0\n",
        "\n",
        "    model_vanilla = VanillaConv2D(kernel).to(device)\n",
        "    model_ptx = PTXConv2D(kernel).to(device)\n",
        "\n",
        "    # Run benchmarks\n",
        "    vanilla_time, vanilla_std = benchmark_model(model_vanilla, input_tensor, \"Vanilla CUDA\")\n",
        "    ptx_time, ptx_std = benchmark_model(model_ptx, input_tensor, \"Inline PTX CUDA\")\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Vanilla CUDA: {vanilla_time:.3f} ms ± {vanilla_std:.3f}\")\n",
        "    print(f\"Inline  PTX: {ptx_time:.3f} ms ± {ptx_std:.3f}\")\n",
        "    print(f\"Speedup (PTX over Vanilla): {vanilla_time / ptx_time:.2f}x\")\n",
        "\n",
        "    # Plot\n",
        "    labels = ['Vanilla CUDA', 'Inline PTX']\n",
        "    times = [vanilla_time, ptx_time]\n",
        "    stds = [vanilla_std, ptx_std]\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    bars = plt.bar(labels, times, yerr=stds, capsize=8, color=['skyblue', 'salmon'])\n",
        "    plt.ylabel('Execution Time (ms)')\n",
        "    plt.title('Convolution Kernel Benchmark (B=4, C=3, H=W=256)')\n",
        "    for bar, t in zip(bars, times):\n",
        "        plt.text(bar.get_x() + bar.get_width() / 2.0, t + 0.5, f\"{t:.2f} ms\", ha='center', va='bottom')\n",
        "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-0cXGPdwiyUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Roofline Plot"
      ],
      "metadata": {
        "id": "pdLDQZbSixQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Define kernel names for comparison\n",
        "kernels = ['Vanilla CUDA Kernel', 'Inline PTX Kernel']\n",
        "\n",
        "# Example arithmetic intensity (FLOPs/byte) — Replace with measured values\n",
        "arithmetic_intensity = [4.0, 6.5]  # e.g., based on estimated memory access and computation\n",
        "\n",
        "# Example achieved performance in GFLOPs/s — Replace with profiled numbers\n",
        "achieved_performance = [900, 1450]\n",
        "\n",
        "# GPU-specific theoretical limits — Update for your actual GPU\n",
        "peak_performance = 17000  # Theoretical peak in GFLOPs/s (e.g., NVIDIA A100)\n",
        "memory_bandwidth = 1555   # Memory bandwidth in GB/s (e.g., A100 HBM2)\n",
        "\n",
        "# X-axis: Arithmetic intensity range\n",
        "intensity_range = np.logspace(-1, 2, 500)  # From 0.1 to 100 FLOPs/byte\n",
        "\n",
        "# Roofline curve: min(compute_bound, memory_bound)\n",
        "roofline = np.minimum(peak_performance, intensity_range * memory_bandwidth)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(intensity_range, roofline, label=\"Theoretical Roofline\", color='black', linewidth=2)\n",
        "plt.scatter(arithmetic_intensity, achieved_performance, color=['blue', 'red'], s=100)\n",
        "\n",
        "# Annotate kernel points\n",
        "for i, kernel in enumerate(kernels):\n",
        "    plt.annotate(kernel,\n",
        "                 (arithmetic_intensity[i], achieved_performance[i]),\n",
        "                 textcoords=\"offset points\",\n",
        "                 xytext=(10, 10),\n",
        "                 ha='left',\n",
        "                 fontsize=10,\n",
        "                 color='darkblue' if i == 0 else 'darkred')\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Arithmetic Intensity (FLOPs/Byte)', fontsize=12)\n",
        "plt.ylabel('Performance (GFLOPs/s)', fontsize=12)\n",
        "plt.title('Roofline Model: Vanilla vs Inline PTX CUDA Kernel', fontsize=14)\n",
        "plt.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eQBjmyDvi3lg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}